{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Author Classification - Stacked LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "xIqGPXw5xCkT",
        "colab_type": "code",
        "outputId": "881105dd-7eb0-4f81-b6ef-0cb3db44d51a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import spacy\n",
        "import gensim\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk import word_tokenize\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, TimeDistributed, Dense, RepeatVector, LSTM, Flatten, Conv1D, Dropout, Conv2D"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "vKDVnH2-D_G6",
        "colab_type": "code",
        "outputId": "0d515cda-f563-4011-9a35-a235dbb3f478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "nltk.download('gutenberg')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "uhINaEhCEApm",
        "colab_type": "code",
        "outputId": "ecaffbaa-af62-476c-93a5-472572844931",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "QgJNg-nnxIhD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# get the data\n",
        "author_text = []\n",
        "paragraphs = []\n",
        "for fileid in nltk.corpus.gutenberg.fileids():\n",
        "    work = nltk.corpus.gutenberg.paras(fileid)\n",
        "    for paragraph in work:\n",
        "        author_text.append(fileid.split('.')[0])\n",
        "        sentences = []\n",
        "        for sentence in paragraph:\n",
        "            sentences += sentence\n",
        "        paragraphs.append(sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4MTULtOVxVRz",
        "colab_type": "code",
        "outputId": "dd75d20f-9473-441c-9947-a472dfa0e60e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print('Number of paragraphs: %d' %len(paragraphs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of paragraphs: 47887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "toHTKpIpzsyf",
        "colab_type": "code",
        "outputId": "6e4dad22-0f7f-431a-e4de-594156599846",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "paragraphs[100]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\"',\n",
              " 'Six',\n",
              " 'years',\n",
              " 'hence',\n",
              " '!',\n",
              " 'Dear',\n",
              " 'Miss',\n",
              " 'Woodhouse',\n",
              " ',',\n",
              " 'he',\n",
              " 'would',\n",
              " 'be',\n",
              " 'thirty',\n",
              " 'years',\n",
              " 'old',\n",
              " '!\"']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "YuCU6ZQmzDtn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# concatenate list of words in to a sentence\n",
        "paragraphs_concatenated = [' '.join(sentence) for sentence in paragraphs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9AeUWiMMzHSE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# simple preprocess by gensim (include lowercase, lemmatize, stem and tokenize, punctuation remove....)\n",
        "paragraphs = [gensim.utils.simple_preprocess(sen) for sen in paragraphs_concatenated]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OEXjvDtZxXgU",
        "colab_type": "code",
        "outputId": "d99e672b-1cf8-4dd0-f9cb-82befb09ffa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "cell_type": "code",
      "source": [
        "paragraphs[100]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['six',\n",
              " 'years',\n",
              " 'hence',\n",
              " 'dear',\n",
              " 'miss',\n",
              " 'woodhouse',\n",
              " 'he',\n",
              " 'would',\n",
              " 'be',\n",
              " 'thirty',\n",
              " 'years',\n",
              " 'old']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "HqPK49ic11fk",
        "colab_type": "code",
        "outputId": "48d3d33e-9da1-4ed9-97cb-54ba097d4f2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print('Total number of tokens: %d'%np.sum([len(i) for i in paragraphs]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of tokens: 2053253\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GGwFu9TM2kG4",
        "colab_type": "code",
        "outputId": "e9a7356c-e298-4398-df86-4150e8b07121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print('Average paragraph length: %d'%np.average([len(i) for i in paragraphs]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average paragraph length: 42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MWyWsQMQIRoG",
        "colab_type": "code",
        "outputId": "7bef3ce5-b505-4abd-d2f4-afd02a07e805",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "cell_type": "code",
      "source": [
        "# describe on the length of paragraph\n",
        "pd.Series([len(i) for i in paragraphs]).describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    47887.000000\n",
              "mean        42.877044\n",
              "std        113.336532\n",
              "min          0.000000\n",
              "25%         16.000000\n",
              "50%         27.000000\n",
              "75%         47.000000\n",
              "max       8783.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "8FOuNJbpIXB2",
        "colab_type": "code",
        "outputId": "0507dfd2-1469-4174-850e-d2606c4a21fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# 95% quantile of length\n",
        "pd.Series([len(i) for i in paragraphs]).quantile(0.95)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "127.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "VC0qWyULIa1n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# pick length = 130\n",
        "MAX_LEN = 130"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y3BrYzYdxrdy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create Word2Vec object\n",
        "# size: Dimensionality of the word vectors.\n",
        "# window: Maximum distance between the current and predicted word within a sentence.\n",
        "# min_count: Ignores all words with total frequency lower than this.\n",
        "# sg: Training algorithm: 1 for skip-gram; otherwise CBOW.\n",
        "# hs: If 1, hierarchical softmax will be used for model training. If 0, and `negative` is non-zero, negative sampling will be used.\n",
        "# negative: If > 0, negative sampling will be used, the int for negative specifies how many \"noise words\"\n",
        "#           should be drawn (usually between 5-20).\n",
        "#           If set to 0, no negative sampling is used.\n",
        "# seed: Seed for the random number generator.\n",
        "# compute_loss: If True, computes and stores loss value which can be retrieved using\n",
        "#               :meth:`~gensim.models.word2vec.Word2Vec.get_latest_training_loss`.\n",
        "# callbacks: Sequence of callbacks to be executed at specific stages during training.\n",
        "\n",
        "model = gensim.models.Word2Vec(paragraphs, size=150, window=5, min_count=1, seed=0, compute_loss=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K6FJZyicx1DX",
        "colab_type": "code",
        "outputId": "d57a743b-14dc-4551-d082-4112087609f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model.train(paragraphs, total_examples=len(paragraphs), epochs=10)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15186447, 20532530)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "vAi089Gq0ApQ",
        "colab_type": "code",
        "outputId": "4286e397-6013-4bfe-bd1d-cbfd18de9044",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print('Latest training loss: %.2f'%model.get_latest_training_loss())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Latest training loss: 0.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KBPHe2LS4UcR",
        "colab_type": "code",
        "outputId": "7a8a34ea-2183-4cc7-e086-a04a13bb6feb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "cell_type": "code",
      "source": [
        "model.wv.most_similar('king', topn=6)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('governor', 0.5235145688056946),\n",
              " ('esther', 0.5107651352882385),\n",
              " ('haman', 0.5050639510154724),\n",
              " ('jehoshaphat', 0.5002504587173462),\n",
              " ('david', 0.4888436198234558),\n",
              " ('solomon', 0.48661303520202637)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "gTbH74sN561e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "paragraphs_embedding = []\n",
        "\n",
        "for paragraph in paragraphs:\n",
        "  paragraph_embedding = []\n",
        "  for word in paragraph:\n",
        "    word_embedding = model.wv.get_vector(word)\n",
        "    paragraph_embedding.append(word_embedding)\n",
        "  paragraphs_embedding.append(paragraph_embedding)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C9mgU951J1og",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# trim and pad embeddign paragraph\n",
        "\n",
        "paragraphs_embedding = sequence.pad_sequences(paragraphs_embedding, maxlen=MAX_LEN, padding='post', truncating='post', value=0.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Z3WPpqSKgBQ",
        "colab_type": "code",
        "outputId": "258af817-2bde-4089-f5b9-3db8765a3cf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# shape after padding & trimming\n",
        "paragraphs_embedding.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47887, 130, 150)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "ptCA4SD16--D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del paragraphs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DKMB__3CLJnt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# transform label data into vector\n",
        "# factorize labels and keep a save record for later reference\n",
        "factorize = pd.factorize(author_text)                                            \n",
        "author_text = np_utils.to_categorical(factorize[0], len(nltk.corpus.gutenberg.fileids()))         "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WQRJYeuoMU2E",
        "colab_type": "code",
        "outputId": "7f5612fd-a7a8-4b3e-c340-9e6efe978fba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "author_text.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47887, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "ViJMv9-yM2sa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# split train test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(paragraphs_embedding, author_text, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9zLeGJZraL9T",
        "colab_type": "code",
        "outputId": "b723a808-7973-4d73-ebad-8a682de7cfc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# CONVOLUTIONAL NEURAL NETWORK\n",
        "\n",
        "cnn = Sequential()\n",
        "cnn.add(Conv1D(150, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=(paragraphs_embedding.shape[1], paragraphs_embedding.shape[2])))\n",
        "cnn.add(Conv1D(100, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dropout(0.5,seed=0))\n",
        "cnn.add(Dense(150))\n",
        "cnn.add(Dense(len(nltk.corpus.gutenberg.fileids())))\n",
        "cnn.add(Activation('softmax'))\n",
        "\n",
        "cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "cnn.summary()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_1 (Conv1D)            (None, 130, 150)          67650     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 130, 100)          45100     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 13000)             0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 13000)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 150)               1950150   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 18)                2718      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 18)                0         \n",
            "=================================================================\n",
            "Total params: 2,065,618\n",
            "Trainable params: 2,065,618\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3OP8FuiIdBSt",
        "colab_type": "code",
        "outputId": "2fea8907-c590-46fc-fb52-9722223b2888",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "cell_type": "code",
      "source": [
        "cnn.fit(X_train, Y_train, batch_size = 128, epochs=20, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "38309/38309 [==============================] - 136s 4ms/step - loss: 1.1302 - acc: 0.6430\n",
            "Epoch 2/20\n",
            "38309/38309 [==============================] - 136s 4ms/step - loss: 0.8328 - acc: 0.7220\n",
            "Epoch 3/20\n",
            "38309/38309 [==============================] - 134s 4ms/step - loss: 0.7066 - acc: 0.7630\n",
            "Epoch 4/20\n",
            "38309/38309 [==============================] - 135s 4ms/step - loss: 0.6292 - acc: 0.7891\n",
            "Epoch 5/20\n",
            "38309/38309 [==============================] - 135s 4ms/step - loss: 0.5616 - acc: 0.8135\n",
            "Epoch 6/20\n",
            "38309/38309 [==============================] - 136s 4ms/step - loss: 0.5138 - acc: 0.8298\n",
            "Epoch 7/20\n",
            "38309/38309 [==============================] - 135s 4ms/step - loss: 0.4605 - acc: 0.8459\n",
            "Epoch 8/20\n",
            "38309/38309 [==============================] - 135s 4ms/step - loss: 0.4370 - acc: 0.8556\n",
            "Epoch 9/20\n",
            "38309/38309 [==============================] - 136s 4ms/step - loss: 0.4173 - acc: 0.8635\n",
            "Epoch 10/20\n",
            "38309/38309 [==============================] - 134s 3ms/step - loss: 0.3972 - acc: 0.8691\n",
            "Epoch 11/20\n",
            "38309/38309 [==============================] - 135s 4ms/step - loss: 0.3705 - acc: 0.8777\n",
            "Epoch 12/20\n",
            "38309/38309 [==============================] - 134s 4ms/step - loss: 0.3428 - acc: 0.8868\n",
            "Epoch 13/20\n",
            "38309/38309 [==============================] - 135s 4ms/step - loss: 0.3397 - acc: 0.8892\n",
            "Epoch 14/20\n",
            "38309/38309 [==============================] - 135s 4ms/step - loss: 0.3252 - acc: 0.8939\n",
            "Epoch 15/20\n",
            "38309/38309 [==============================] - 136s 4ms/step - loss: 0.3207 - acc: 0.8959\n",
            "Epoch 16/20\n",
            "38309/38309 [==============================] - 135s 4ms/step - loss: 0.3062 - acc: 0.9004\n",
            "Epoch 17/20\n",
            "38309/38309 [==============================] - 135s 4ms/step - loss: 0.3018 - acc: 0.9022\n",
            "Epoch 18/20\n",
            "38309/38309 [==============================] - 136s 4ms/step - loss: 0.3009 - acc: 0.9032\n",
            "Epoch 19/20\n",
            "38309/38309 [==============================] - 135s 4ms/step - loss: 0.2787 - acc: 0.9100\n",
            "Epoch 20/20\n",
            "38309/38309 [==============================] - 136s 4ms/step - loss: 0.2904 - acc: 0.9080\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9a3b132da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "CNFkbpD_dQoC",
        "colab_type": "code",
        "outputId": "8dab2b71-3917-4d62-baaf-69577197817c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# predict on test dataset\n",
        "predict_label_cnn = cnn.predict(X_test, batch_size = 128, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9578/9578 [==============================] - 11s 1ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VDh2qGsldQkW",
        "colab_type": "code",
        "outputId": "fef7fd50-6ba4-4413-b3ff-eebb3bb9a9e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "# turn the predict vector to final predict base on argmax\n",
        "predict_label_cnn = [np.argmax(i) for i in predict_label_cnn]\n",
        "# turn the test labels vector to final label base on argmax\n",
        "Y_test_cnn = [np.argmax(i) for i in Y_test]\n",
        "# classification report\n",
        "print(classification_report(Y_test_cnn, predict_label_cnn))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.75      0.75       480\n",
            "           1       0.83      0.49      0.61       211\n",
            "           2       0.70      0.65      0.68       371\n",
            "           3       0.94      0.99      0.97      4880\n",
            "           4       0.32      0.11      0.16        66\n",
            "           5       0.68      0.30      0.41       269\n",
            "           6       0.98      0.62      0.76        68\n",
            "           7       0.72      0.72      0.72       174\n",
            "           8       0.83      0.50      0.63       330\n",
            "           9       0.52      0.39      0.45       232\n",
            "          10       0.50      0.59      0.54       232\n",
            "          11       0.58      0.78      0.66       722\n",
            "          12       0.73      0.68      0.70       550\n",
            "          13       0.00      0.00      0.00         8\n",
            "          14       0.69      0.49      0.57       165\n",
            "          15       0.66      0.62      0.64       202\n",
            "          16       0.27      0.39      0.32       117\n",
            "          17       0.63      0.69      0.66       501\n",
            "\n",
            "   micro avg       0.80      0.80      0.80      9578\n",
            "   macro avg       0.63      0.54      0.57      9578\n",
            "weighted avg       0.81      0.80      0.80      9578\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "H-tLTXA67YxE",
        "colab_type": "code",
        "outputId": "b48ee430-7db2-4860-a5ea-eee9d9f3306f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "cell_type": "code",
      "source": [
        "# STACKED LSTM\n",
        "\n",
        "HIDDEN_SIZE = 256\n",
        "\n",
        "stacked_lstm = Sequential()\n",
        "stacked_lstm.add(LSTM(HIDDEN_SIZE, input_shape=(paragraphs_embedding.shape[1], paragraphs_embedding.shape[2])))\n",
        "stacked_lstm.add(RepeatVector(MAX_LEN))\n",
        "stacked_lstm.add(LSTM(HIDDEN_SIZE, return_sequences=True))\n",
        "stacked_lstm.add(LSTM(HIDDEN_SIZE, return_sequences=True))\n",
        "\n",
        "stacked_lstm.add(TimeDistributed(Dense(len(nltk.corpus.gutenberg.fileids()))))\n",
        "stacked_lstm.add(Flatten())\n",
        "stacked_lstm.add(Dense(len(nltk.corpus.gutenberg.fileids())))\n",
        "stacked_lstm.add(Activation('softmax'))\n",
        "\n",
        "stacked_lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "stacked_lstm.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 256)               416768    \n",
            "_________________________________________________________________\n",
            "repeat_vector_1 (RepeatVecto (None, 130, 256)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 130, 256)          525312    \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 130, 256)          525312    \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 130, 18)           4626      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2340)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 18)                42138     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 18)                0         \n",
            "=================================================================\n",
            "Total params: 1,514,156\n",
            "Trainable params: 1,514,156\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sEy9Ar6hOQIQ",
        "colab_type": "code",
        "outputId": "6655010e-be10-49a5-8fc5-1638b9a4f405",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "cell_type": "code",
      "source": [
        "stacked_lstm.fit(X_train, Y_train, batch_size = 512, epochs=20, verbose=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "38309/38309 [==============================] - 1196s 31ms/step - loss: 1.9855 - acc: 0.5162\n",
            "Epoch 2/20\n",
            "38309/38309 [==============================] - 1186s 31ms/step - loss: 1.4474 - acc: 0.5788\n",
            "Epoch 3/20\n",
            "38309/38309 [==============================] - 1188s 31ms/step - loss: 1.1589 - acc: 0.6231\n",
            "Epoch 4/20\n",
            "38309/38309 [==============================] - 1186s 31ms/step - loss: 1.0791 - acc: 0.6463\n",
            "Epoch 5/20\n",
            "38309/38309 [==============================] - 1185s 31ms/step - loss: 1.0233 - acc: 0.6599\n",
            "Epoch 6/20\n",
            "38309/38309 [==============================] - 1187s 31ms/step - loss: 0.9894 - acc: 0.6701\n",
            "Epoch 7/20\n",
            "38309/38309 [==============================] - 1194s 31ms/step - loss: 0.9570 - acc: 0.6784\n",
            "Epoch 8/20\n",
            "38309/38309 [==============================] - 1192s 31ms/step - loss: 0.9117 - acc: 0.6987\n",
            "Epoch 9/20\n",
            "38309/38309 [==============================] - 1194s 31ms/step - loss: 0.8801 - acc: 0.7072\n",
            "Epoch 10/20\n",
            "38309/38309 [==============================] - 1189s 31ms/step - loss: 0.7831 - acc: 0.7369\n",
            "Epoch 11/20\n",
            "38309/38309 [==============================] - 1187s 31ms/step - loss: 0.7449 - acc: 0.7519\n",
            "Epoch 12/20\n",
            "38309/38309 [==============================] - 1190s 31ms/step - loss: 0.7306 - acc: 0.7657\n",
            "Epoch 13/20\n",
            "38309/38309 [==============================] - 1185s 31ms/step - loss: 0.6715 - acc: 0.7862\n",
            "Epoch 14/20\n",
            "38309/38309 [==============================] - 1185s 31ms/step - loss: 0.6016 - acc: 0.8076\n",
            "Epoch 15/20\n",
            "38309/38309 [==============================] - 1182s 31ms/step - loss: 0.5752 - acc: 0.8189\n",
            "Epoch 16/20\n",
            "38309/38309 [==============================] - 1185s 31ms/step - loss: 0.8494 - acc: 0.7507\n",
            "Epoch 17/20\n",
            "38309/38309 [==============================] - 1185s 31ms/step - loss: 0.8948 - acc: 0.7307\n",
            "Epoch 18/20\n",
            "38309/38309 [==============================] - 1181s 31ms/step - loss: 0.7021 - acc: 0.7820\n",
            "Epoch 19/20\n",
            "38309/38309 [==============================] - 1189s 31ms/step - loss: 0.5837 - acc: 0.8123\n",
            "Epoch 20/20\n",
            "38309/38309 [==============================] - 1186s 31ms/step - loss: 0.5198 - acc: 0.8277\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe6bea8ff60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "kblO2EEZ-0jy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c61d21b9-5335-4454-eab6-b875f23381c1"
      },
      "cell_type": "code",
      "source": [
        "# predict on test dataset\n",
        "predict_label_lstm = stacked_lstm.predict(X_test, batch_size = 512, verbose = 1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9578/9578 [==============================] - 104s 11ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vmpifCouAP71",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "27abcf97-a427-47b6-bd40-2b3fa0edfc4a"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "# turn the predict vector to final predict base on argmax\n",
        "predict_label_lstm = [np.argmax(i) for i in predict_label_lstm]\n",
        "# turn the test labels vector to final label base on argmax\n",
        "Y_test_lstm = [np.argmax(i) for i in Y_test]\n",
        "# classification report\n",
        "print(classification_report(Y_test_lstm, predict_label_lstm))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.76      0.79       480\n",
            "           1       0.92      0.60      0.72       211\n",
            "           2       0.84      0.66      0.74       371\n",
            "           3       0.96      0.99      0.97      4880\n",
            "           4       0.20      0.06      0.09        66\n",
            "           5       0.46      0.38      0.42       269\n",
            "           6       0.84      0.68      0.75        68\n",
            "           7       0.90      0.47      0.62       174\n",
            "           8       0.80      0.48      0.60       330\n",
            "           9       0.52      0.51      0.51       232\n",
            "          10       0.52      0.59      0.55       232\n",
            "          11       0.61      0.76      0.68       722\n",
            "          12       0.71      0.65      0.68       550\n",
            "          13       0.00      0.00      0.00         8\n",
            "          14       0.34      0.72      0.46       165\n",
            "          15       0.36      0.06      0.11       202\n",
            "          16       0.27      0.05      0.09       117\n",
            "          17       0.50      0.82      0.62       501\n",
            "\n",
            "   micro avg       0.80      0.80      0.80      9578\n",
            "   macro avg       0.59      0.51      0.52      9578\n",
            "weighted avg       0.80      0.80      0.79      9578\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "tFlDc9vHAF0F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NEz2YvGugDHV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}